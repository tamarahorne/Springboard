{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This works.  Don't delete it.\n",
    "\n",
    "#high_single = data_corr_high['gene_20397'][data_corr_high['gene_20397']!=0][data_corr_high['gene_20397']!=1]\n",
    "#high_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c76259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't delete this - this shows promise but still needs alteration\n",
    "\n",
    "#for i in data_corr_high:\n",
    "#    high[i] = data_corr_high[i][data_corr_high[i]!=0][data_corr_high[i]!=1]\n",
    "#    print(high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is getting really close - don't delete\n",
    "\n",
    "high_single_df2 = pd.DataFrame()\n",
    "\n",
    "high_single = data_corr_high['gene_20397'][data_corr_high['gene_20397']!=0][data_corr_high['gene_20397']!=1]\n",
    "\n",
    "high_single_df2['corr'] = high_single\n",
    "high_single_df2 = high_single_df2.reset_index()\n",
    "high_single_df2.rename(columns={'index': 'gene_B'}, inplace=True)\n",
    "high_single_df2['gene_A'] = 'gene_20397'\n",
    "high_single_df2 = high_single_df2[['gene_A','gene_B','corr']]\n",
    "high_single_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_single_df5 = pd.DataFrame()\n",
    "\n",
    "high_single = data_corr_high['gene_13442'][data_corr_high['gene_13442']!=0][data_corr_high['gene_13442']!=1]\n",
    "\n",
    "high_single_df5['corr'] = high_single\n",
    "high_single_df5 = high_single_df5.reset_index()\n",
    "high_single_df5.rename(columns={'index': 'gene_B'}, inplace=True)\n",
    "high_single_df5['gene_A'] = 'gene_13442'\n",
    "high_single_df5 = high_single_df5[['gene_A','gene_B','corr']]\n",
    "high_single_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d2b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames = [high_single_df2, high_single_df5]\n",
    "\n",
    "result = pd.concat([high_single_df2, high_single_df5])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa0117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if i in all_gene_df:\n",
    "#    for j in all_gene_df:\n",
    "#        if (i[0], i[1], i[2]) == (j[1], j[0], j[2]):\n",
    "#            if j != i:\n",
    "#                print('same')\n",
    "#            else:\n",
    "#                print('remove')\n",
    "#        else:\n",
    "#            print('nothing happened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse_gene_df = all_gene_df.copy()\n",
    "#reverse_gene_df.rename(columns={'gene_A': 'gene_B', 'gene_B': 'gene_A'}, inplace=True)\n",
    "#reverse_gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ff99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform anti-join on all_gene_df to exclude duplicate correlation pairs.\n",
    "\n",
    "#outer = all_gene_df.merge(reverse_gene_df, on=['gene_A','gene_B','corr'], how='outer', indicator=True)\n",
    "#final_gene_df = outer[(outer._merge=='left_only')].drop('_merge', axis=1)\n",
    "#final_gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig, ax =plt.subplots(1,1,figsize=(20,500))\n",
    "\n",
    "\n",
    "#ax1 = sns.barplot(data=df_max_min, y = 'index', x = 'max', alpha=0.5)\n",
    "#ax2 = sns.barplot(data=df_max_min, y = 'index', x = 'min')\n",
    "#ax1.set_title('Max and Min for Each Column', fontsize=20, pad=20)\n",
    "#ax1.set_xlabel('Max and Min', fontsize=14)\n",
    "#ax1.set_ylabel('Column', fontsize=14)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA (or other dimensional reduction) before fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f1d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "510b4314",
   "metadata": {},
   "source": [
    "Could possibly need this later....creat a scatterplot of 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data.iloc[:, [0,2,3,4,5,6]].copy()\n",
    "data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba30603",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Unnamed: 0'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp['Unnamed: 0'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939227df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_joined = data_temp.merge(labels)\n",
    "\n",
    "#temp_joined = data_temp.join(labels, how='left', on = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cccb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp_joined.drop(['Unnamed: 0', 'Class'], axis = 1)\n",
    "y = temp_joined['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining X and y\n",
    "\n",
    "#X = data.drop(['Unnamed: 0'], axis = 1)\n",
    "#y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b06f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=Counter(y)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20799b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I need to get X to be an array like it is with x in the make_classifiction data below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e572717",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = X.to_numpy\n",
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAD_rows = []\n",
    "LUAD_rows = []\n",
    "BRCA_rows = []\n",
    "KIRC_rows = []\n",
    "COAD_rows = []\n",
    "\n",
    "for label, quantity in counter.items():\n",
    "    row_id = where (y == label)[0]\n",
    "    if label == 'PRAD':\n",
    "        PRAD_rows.append(row_id)\n",
    "    if label == 'LUAD':\n",
    "        LUAD_rows.append(row_id)\n",
    "    if label == 'BRCA':\n",
    "        BRCA_rows.append(row_id)\n",
    "    if label == 'KIRC':\n",
    "        KIRC_rows.append(row_id)\n",
    "    if label == 'COAD':\n",
    "        COAD_rows.append(row_id)\n",
    "print('PRAD_rows:', PRAD_rows)\n",
    "print('LUAD_rows:', LUAD_rows)\n",
    "print('BRCA_rows:', BRCA_rows)    \n",
    "print('KIRC_rows:', KIRC_rows)\n",
    "print('COAD_rows:', COAD_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_joined.head()\n",
    "temp_2 = temp_joined.drop(['Unnamed: 0'], axis=1)\n",
    "temp_3 = temp_joined.drop(['Unnamed: 0', 'gene_2', 'gene_3', 'gene_4', 'gene_5'], axis=1)\n",
    "temp_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaaee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can only use two feature, three with hue, 4 with style\n",
    "\n",
    "sns.scatterplot(data=temp_2, x=\"gene_1\", y=\"gene_2\", hue=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea787d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for label, _ in counter.items():\n",
    "#    row_id = where (y == label)[0]\n",
    "#    plt.scatter(X[row_id,'PRAD'], X[row_id,'LUAD'], X[row_id,'BRCA'], X[row_id,'KIRC'], X[row_id,'COAD'])\n",
    "#    #plt.scatter(X[2,0], label=str(label))\n",
    "#    plt.legend()\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f98cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26367e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0\n",
    "\n",
    "#for i in data_var:  \n",
    "#    if i>0 and i<1:\n",
    "#        count += 1\n",
    "#print('Number of columns whose values have variance greater than 0 but less than 1:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac4cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model (dim_red, model):\n",
    "    # execute a model pipeline and print the classification reports for\n",
    "    # both the training and testing data\n",
    "    \n",
    "    steps = [('pca', dim_red),\n",
    "             ('clf', model)]\n",
    "    pipe = Pipeline(steps)\n",
    "\n",
    "    pipe.fit(X_train, y_train.values.ravel())\n",
    "          \n",
    "    y_pred_test = pipe.predict(X_test)\n",
    "    y_pred_train = pipe.predict(X_train)\n",
    "    \n",
    "    # get individual values from training data classification report\n",
    "    report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "    macro_precision_train =  report_train['macro avg']['precision'] \n",
    "    macro_recall_train = report_train['macro avg']['recall']    \n",
    "    macro_f1_train = report_train['macro avg']['f1-score']\n",
    "    \n",
    "    # get inidividual values from test data classification report\n",
    "    report_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "    macro_precision_test =  report_test['macro avg']['precision'] \n",
    "    macro_recall_test = report_test['macro avg']['recall']    \n",
    "    macro_f1_test = report_test['macro avg']['f1-score']\n",
    "    \n",
    "    print('macro_f1_train: ', macro_f1_train)\n",
    "    print('macro_f1_test: ', macro_f1_test)    \n",
    "\n",
    "    print(\"Train set classification report:\\n\", classification_report(y_train, y_pred_train))\n",
    "    print(\"Test set classification report:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_curve_plots (OneVsRestClassifier(LinearSVC(max_iter=5000, random_state=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_model(StandardScaler(), PCA(n_components=7), xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_model(StandardScaler(), PCA(n_components=7), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48417867/access-to-numbers-in-classification-report-sklearn\n",
    "\n",
    "#report = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "#macro_precision =  report['macro avg']['precision'] \n",
    "#macro_recall = report['macro avg']['recall']    \n",
    "#macro_f1 = report['macro avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a loop - \n",
    "### dict of all model types \n",
    "### for every model, grab the macro_f1_score and then append them to a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e63581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbcl = xgb.XGBClassifier()\n",
    "#xgbcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_test = xgbcl.predict(X_test)\n",
    "#y_pred_train = xgbcl.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa198d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()),\n",
    "         ('pca', PCA(n_components=7)),\n",
    "         ('clf', xgb.XGBClassifier())]\n",
    "#         ('clf', LogisticRegression())]\n",
    "pipe_xgbcl = Pipeline(steps)\n",
    "\n",
    "pipe_xgbcl.fit(X_train, y_train)\n",
    "          \n",
    "y_pred_test_xgbcl = pipe_xgbcl.predict(X_test)\n",
    "y_pred_train_xgbcl = pipe_xgbcl.predict(X_train)\n",
    "\n",
    "### XGB is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set classification report:\\n\", classification_report(y_train, y_pred_train_xgbcl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set classification report:\\n\", classification_report(y_test, y_pred_test_xgbcl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code adapted from https://stackoverflow.com/questions/45332410/roc-for-multiclass-classification\n",
    "\n",
    "def get_roc_curve_plots (CLF):\n",
    "    \n",
    "    y_bin = label_binarize(y, classes=[0,1,2,3,4])\n",
    "    n_classes = 5\n",
    "\n",
    "    # split training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    # classifier\n",
    "    clf = CLF\n",
    "    y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot of a ROC curve for a specific class\n",
    "    for i in range(n_classes):\n",
    "        plt.figure()\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC for Class ' + str(i))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f27eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One vs the rest\n",
    "#roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Area Under the Curve\n",
    "# One vs the rest\n",
    "roc_auc_score(y, pipe_lr.predict_proba(X), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_proba = pipe_lr.predict_proba(X_test)\n",
    "#classes = pipe_lr.classes_\n",
    "#for i in range(len(classes)):\n",
    "#    # Gets the class\n",
    "#    c = classes[i]\n",
    "\n",
    "#    df_aux = X_test.copy()\n",
    "#    for y in y_test.values.ravel():\n",
    "#        if y == c:\n",
    "#            df_aux['class'] = 1\n",
    "#        else:\n",
    "#            df_aux['class'] = 0\n",
    "#    #df_aux['class'] = [1 if y == c else 0 for y in y_test]\n",
    "#    df_aux['prob'] = y_proba[:, i]\n",
    "#    df_aux = df_aux.reset_index(drop = True)\n",
    "    \n",
    "\n",
    "#roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RocCurveDisplay.from_predictions(y_test, y_pred_test_lr)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not my code\n",
    "\n",
    "#y_proba = pipe_lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "\n",
    "https://medium.com/@kennymiyasato/classification-report-precision-recall-f1-score-accuracy-16a245a437a5\n",
    "\n",
    "https://stephenallwright.com/f1-score-vs-auc/\n",
    "\n",
    "https://www.mariakhalusova.com/posts/2019-04-17-ml-model-evaluation-metrics-p2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/pouryaayria/a-complete-ml-pipeline-tutorial-acu-86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205856a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bf2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8464a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with PCA, and Logistic Regression where multi_class=ovr\n",
    "steps_ovr = [('pca', PCA(n_components=7)),\n",
    "         ('clf', LogisticRegression(max_iter = 5000, multi_class='ovr'))]\n",
    "\n",
    "pipe_lr_ovr = Pipeline(steps_ovr)\n",
    "\n",
    "pipe_lr_ovr.fit(X_train, y_train.values.ravel())\n",
    "          \n",
    "y_pred_test_lr_ovr = pipe_lr_ovr.predict(X_test)\n",
    "y_pred_train_lr_ovr = pipe_lr_ovr.predict(X_train)\n",
    "\n",
    "# https://machinelearningmastery.com/multinomial-logistic-regression-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the training data\n",
    "print(\"Train set classification report:\\n\", classification_report(y_train, y_pred_train_lr_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f865d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the testing data\n",
    "print(\"Test set classification report:\\n\", classification_report(y_test, y_pred_test_lr_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfedb4",
   "metadata": {},
   "source": [
    "Changing the multi_class option to 'ovr' lowers the predictive power in the training data ever so slightly but it increases the macro-avg f1 score for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b71cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for logistic regression model\n",
    "#multilabel_confusion_matrix_not_scaled_ovr = confusion_matrix(y_test, y_pred_test_lr_ovr)\n",
    "# Create a pipeline with PCA and Logistic Regression\n",
    "steps = [('pca', PCA(n_components=7)),\n",
    "         ('clf', LogisticRegression(max_iter = 5000, multi_class='auto'))]\n",
    "pipe_lr = Pipeline(steps)\n",
    "\n",
    "pipe_lr.fit(X_train, y_train.values.ravel())\n",
    "          \n",
    "y_pred_test_lr = pipe_lr.predict(X_test)\n",
    "y_pred_train_lr = pipe_lr.predict(X_train)\n",
    "\n",
    "multilabel_confusion_matrix = confusion_matrix(y_test, y_pred_test_lr)\n",
    "multilabel_confusion_matrix_ovr = confusion_matrix(y_test, y_pred_test_lr_ovr)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(1,2,figsize=(14,6))\n",
    "fig.suptitle(\"Confusion Matrix for Baseline Model: Logistic Regression\", fontsize=20, y=1.0)\n",
    "\n",
    "sns.heatmap(multilabel_confusion_matrix, cmap='crest', annot=True, ax=ax[0])\n",
    "ax[0].set_title(\"multi_class = multinomial/auto\", fontsize=15)\n",
    "ax[0].set(ylabel=\"True\", xlabel=\"Predicted\")\n",
    "\n",
    "sns.heatmap(multilabel_confusion_matrix_ovr, cmap='crest', annot=True, ax=ax[1])\n",
    "ax[1].set_title(\"multi_class = ovr\", fontsize=15)\n",
    "ax[1].set(ylabel=\"True\", xlabel=\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial rf\n",
    "\n",
    "# rf scoring method = oob_score_\n",
    "param_grid_rf = [{\n",
    "    'clf__n_estimators':[100, 500, 1000, 2000, 3000, 4000, 5000], \n",
    "    'clf__max_features': ['log2', 'sqrt', 'None'], \n",
    "    'clf__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'clf__min_samples_leaf': [1, 2, 4], \n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__bootstrap': [True], \n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'clf__random_state':[42],\n",
    "    'clf__max_samples': [0.8],\n",
    "    'clf__warm_start':[True]\n",
    "}]\n",
    "\n",
    "def custom_scorer (pipeline):\n",
    "    oob_error = 1 - pipeline['clf'].oob_score_\n",
    "    return [oob_error]\n",
    "    \n",
    "def tune_model (clf, param_grid, score_method):\n",
    "    \n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    pipeline = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', clf)])\n",
    "\n",
    "    CV = GridSearchCV(pipeline, param_grid, scoring = pipe['clf'].oob_score_, n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #print('Best score:', CV.best_score_)\n",
    "    #print('\\nBest parameter combination:', CV.best_params_)\n",
    "    return\n",
    "\n",
    "#tune_model(LogisticRegression(random_state=42, max_iter = 5000), param_grid_lr, 'f1_macro')\n",
    "tune_model(RandomForestClassifier(), param_grid_rf, pipeline['clf'].oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba006115",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('pca', PCA(n_components=7)),\n",
    "         ('clf', RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500))]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Obtain the OOB error\n",
    "oob_error = 1 - pipe['clf'].oob_score_\n",
    "  \n",
    "# Print the OOB error\n",
    "print('OOB error:', oob_error.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['clf'].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-pipe['clf'].oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {#'Logistic Regression': LogisticRegression(max_iter = 5000, multi_class='auto', random_state=42),#\n",
    "         'Random Forest': RandomForestClassifier(random_state=42),\n",
    "          #'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "          #'Naive Bayes': GaussianNB(),\n",
    "          #'Support Vector Machine': SVC(max_iter = 5000, random_state=42),\n",
    "          #'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "          #'XGBoost': XGBClassifier(random_state=42),\n",
    "          #'Light Gradient Boosting': LGBMClassifier(random_state=42),\n",
    "          #'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "         }\n",
    "\n",
    "param_grid_rf = [{\n",
    "    'n_estimators':[100, 500], \n",
    "    'max_features': ['log2'], \n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_leaf': [1], \n",
    "    'min_samples_split': [2],\n",
    "    'bootstrap': [True], \n",
    "    'oob_score': [True],\n",
    "    'criterion': ['gini'],\n",
    "    'random_state':[42],\n",
    "    'max_samples': [0.8],\n",
    "    'warm_start':[True]\n",
    "}]\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "def execute_model (models, param_grid):\n",
    "    \n",
    "    # Create a dataframe of model names and the mean f1 macro averaged score \n",
    "    # across five folds using StratifyKFold\n",
    "\n",
    "    model_names_list = []\n",
    "    model_params_list = []\n",
    "    model_oob_score_list = []\n",
    "\n",
    "    for name, model, in models.items():\n",
    "        \n",
    "        # execute each model from list of models\n",
    "        \n",
    "        clf = model\n",
    "\n",
    "        CV = GridSearchCV(model, param_grid, n_jobs= 1)\n",
    "        CV.fit(X_train_pca, y_train.values.ravel())\n",
    "        \n",
    "        # get the f1 macro averaged score for each fold and then find the mean\n",
    "        scores = clf.oob_score_\n",
    "        #mean = np.mean(scores).round(5)\n",
    "        \n",
    "        # appeand the names and means to lists\n",
    "        model_names_list.append(name)\n",
    "        #model_params_list.append(mean)\n",
    "        model_oob_score_list.append(score)\n",
    "        \n",
    "    # create a dataframe from the lists\n",
    "    model_df = pd.DataFrame({'names':model_names_list, 'oob_score': model_oob_score_list})\n",
    "\n",
    "    return model_df\n",
    "\n",
    "# sort the dataframe by mean score in descending order and print\n",
    "print('Mean of f1 macro average from 5 stratified folds on training data for out of the box models:')\n",
    "model_df = execute_model(models, param_grid_rf)\n",
    "model_df = model_df.sort_values(by = 'oob_score', ascending=False)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3533de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial rf with reduced params for speed\n",
    "# this works with no scorer\n",
    "param_grid_rf = [{\n",
    "    'n_estimators':[100, 500], \n",
    "    'max_features': ['log2'], \n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_leaf': [1], \n",
    "    'min_samples_split': [2],\n",
    "    'bootstrap': [True], \n",
    "    'oob_score': [True],\n",
    "    'criterion': ['gini'],\n",
    "    'random_state':[42],\n",
    "    'max_samples': [0.8],\n",
    "    'warm_start':[True]\n",
    "}]\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "  \n",
    "def tune_model (clf, param_grid):\n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    def custom_scorer_func (a,b):\n",
    "        oob_error = clf.oob_score_\n",
    "        return [oob_error]\n",
    "    custom_scorer = make_scorer(custom_scorer_func, greater_is_better=False)\n",
    "\n",
    "    CV = GridSearchCV(clf, param_grid, n_jobs= 1, scoring = custom_scorer)\n",
    "    CV.fit(X_train_pca, y_train.values.ravel())\n",
    "    \n",
    "    print('Best score:', CV.best_score_)\n",
    "    print('\\nBest parameter combination:', CV.best_params_)\n",
    "\n",
    "    return\n",
    "\n",
    "tune_model(RandomForestClassifier(), param_grid_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = [{\n",
    "    'clf__n_estimators':[100, 500, 1000, 2000, 3000, 4000, 5000], \n",
    "    'clf__max_features': ['log2', 'sqrt', 'None'], \n",
    "    'clf__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'clf__min_samples_leaf': [1, 2, 4], \n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__bootstrap': [True], \n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'clf__random_state':[42],\n",
    "    'clf__max_samples': [0.8],\n",
    "    'clf__warm_start':[True]\n",
    "}]\n",
    "\n",
    "steps = [#('pca', PCA(n_components=7)),\n",
    "         ('clf', RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500))]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "def custom_score_func (pipeline):\n",
    "    oob_error = 1 - pipeline['clf'].oob_score_\n",
    "    return oob_error\n",
    "#custom_scorer_func(pipe)\n",
    "\n",
    "custom_scorer = make_scorer(custom_score_func, greater_is_better=False)\n",
    "\n",
    "CV = GridSearchCV(pipe, param_grid_rf, scoring = custom_scorer)\n",
    "CV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "#custom_scorer(pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced param grid for speed\n",
    "\n",
    "\n",
    "\n",
    "param_grid_rf = [{\n",
    "    'clf__n_estimators':[100, 500], \n",
    "    'clf__max_features': ['log2'], \n",
    "    'clf__max_depth': [10, 20],\n",
    "    'clf__min_samples_leaf': [1], \n",
    "    'clf__min_samples_split': [2],\n",
    "    'clf__bootstrap': [True], \n",
    "    'clf__oob_score': [True],\n",
    "    'clf__criterion': ['gini'],\n",
    "    'clf__random_state':[42],\n",
    "    'clf__max_samples': [0.8],\n",
    "    'clf__warm_start':[True]\n",
    "}]\n",
    "\n",
    "steps = [('pca', PCA(n_components=7)),\n",
    "         ('clf', RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500))]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "def custom_scorer (pipeline):\n",
    "    oob_error = 1 - pipeline['clf'].oob_score_\n",
    "    return oob_error\n",
    "custom_scorer('clf')\n",
    "\n",
    "CV = GridSearchCV(pipe, param_grid_rf, scoring = make_scorer(custom_scorer, greater_is_better=False), n_jobs= 1)\n",
    "CV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "#custom_scorer(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is complete and works\n",
    "\n",
    "param_grid_lr = [\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['liblinear'], 'clf__penalty': ['l1','l2']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['lbfgs'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['sag'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['saga'], 'clf__penalty': ['l1','l2','none']},\n",
    "    # failed to converge even with max_iter=10000   {'clf__multi_class': ['ovr'], 'clf__solver': ['newton-cg'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['lbfgs'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['sag'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['saga'], 'clf__penalty': ['l1','l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['newton-cg'], 'clf__penalty': ['l2','none']},\n",
    "]\n",
    "\n",
    "\n",
    "def tune_model (clf, param_grid):\n",
    "    \n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    pipeline = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', clf)])\n",
    "\n",
    "    CV = GridSearchCV(pipeline, param_grid, scoring = 'f1_macro', n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    return CV.best_score_, CV.best_params_\n",
    "\n",
    "tune_model(LogisticRegression(random_state=42, max_iter = 5000), param_grid_lr)\n",
    "best_score_lr, best_params_lr = tune_model(LogisticRegression(random_state=42, max_iter = 5000), param_grid_lr)\n",
    "print('Best score:', best_score_lr)\n",
    "print('\\nBest parameter combination:', best_params_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a final baseline model with the best parameters found in grid search\n",
    "tuned_pipe_lr = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', LogisticRegression(random_state=42, max_iter = 5000,\n",
    "                                                  multi_class='ovr',penalty='l1',\n",
    "                                                  solver='liblinear'))])\n",
    "\n",
    "tuned_pipe_lr.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "\n",
    "# Use StratifyKFold for cross validation\n",
    "k = 5\n",
    "cv = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n",
    "scores = cross_val_score(tuned_pipe_lr, X_train, y_train.values.ravel(), scoring='f1_macro', cv=cv)\n",
    "\n",
    "print(\"Scores for each fold of tuned baseline model\\n\")\n",
    "for i in range (0,k):\n",
    "    print('Fold number: %d, F1_macro_avg: %.3f' %(i, scores[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a final baseline model with the best parameters found in grid search\n",
    "tuned_pipe_lr = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', LogisticRegression(random_state=42, max_iter = 5000,\n",
    "                                                  multi_class='ovr',penalty='l1',\n",
    "                                                  solver='liblinear'))])\n",
    "\n",
    "\n",
    "    \n",
    "def get_folds (pipeline):\n",
    "    # gets f1 macro avg scores for five folds of data from a pipeline\n",
    "    \n",
    "    pipeline.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Use StratifyKFold for cross validation\n",
    "    k = 5\n",
    "    cv = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train.values.ravel(), scoring='f1_macro', cv=cv)\n",
    "\n",
    "    print(\"Scores for each fold of tuned baseline model\\n\")\n",
    "    for i in range (0,k):\n",
    "        print('Fold number: %d, F1_macro_avg: %.3f' %(i, scores[i]))\n",
    "\n",
    "get_folds(tuned_pipe_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72826baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial\n",
    "\n",
    "param_grid_knn = [{\n",
    "    'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "    'clf__weights': ['uniform','distance'],\n",
    "    'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "    'clf__p': [1,2]\n",
    "}]\n",
    "\n",
    "\n",
    "param_grid_lr = [\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['liblinear'], 'clf__penalty': ['l1','l2']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['lbfgs'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['sag'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['ovr'], 'clf__solver': ['saga'], 'clf__penalty': ['l1','l2','none']},\n",
    "    # failed to converge even with max_iter=10000   {'clf__multi_class': ['ovr'], 'clf__solver': ['newton-cg'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['lbfgs'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['sag'], 'clf__penalty': ['l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['saga'], 'clf__penalty': ['l1','l2','none']},\n",
    "    {'clf__multi_class': ['multinomial'], 'clf__solver': ['newton-cg'], 'clf__penalty': ['l2','none']},\n",
    "]\n",
    "\n",
    "\n",
    "# rf scoring method = oob_score_\n",
    "param_grid_rf = [{\n",
    "    'n_estimators':[100, 500, 1000, 2000, 3000, 4000, 5000], \n",
    "    'max_features': ['log2', 'sqrt', 'None'], \n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True], \n",
    "    'oob_score': True,\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state':42,\n",
    "    'max_samples': 0.8,\n",
    "    'warm_start':True\n",
    "}]\n",
    "\n",
    "\n",
    "param_grid_svm = [{\n",
    "    'clf__kernel': ['linear','poly','rbf','sigmoid'],\n",
    "    'clf__C': [0.1,1,10,100],\n",
    "    'clf__gamma': [1,0.1,0.01,0.001]\n",
    "}]\n",
    "\n",
    "\n",
    "#    param_grid_lgb = {\n",
    "#        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss']),\n",
    "#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "#        'num_leaves': trial.suggest_int('num_leaves', 2, 256, log=True),\n",
    "#        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "#        'min_child_samples': trial.suggest_int('min_child_samples', 2, 256, log=True),\n",
    "#        'bagging_freq': trial.suggest_categorical('bagging_freq', [0, 1]),\n",
    "#        'pos_bagging_fraction': trial.suggest_float('pos_bagging_fraction', 0.1, 1),\n",
    "#        'neg_bagging_fraction': trial.suggest_float('neg_bagging_fraction', 0.1, 1),\n",
    "#        'reg_alpha': trial.suggest_float('reg_alpha', 0.00001, 0.1, log=True),\n",
    "#        'reg_lambda': trial.suggest_float('reg_lambda', 0.00001, 0.1, log=True),\n",
    "#    }\n",
    "    \n",
    "    \n",
    "param_grid_xgb = [{\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.5, 1.0, 0.1],\n",
    "    'gamma': [1,2,3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "    'colsample_bytree' : [0.1, 0.5, 1],\n",
    "    'min_child_weight' : [0,1,2,3,4,5,6,7,8,9],\n",
    "    ###    'n_estimators': 180,\n",
    "    'seed': 42\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec89511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working code - single rf params not grid\n",
    "\n",
    "steps = [('pca', PCA(n_components=7)),\n",
    "         ('clf', RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500))]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Obtain the OOB error\n",
    "oob_error = 1 - pipe['clf'].oob_score_\n",
    "  \n",
    "# Print the OOB error\n",
    "print('OOB error:', oob_error.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d575d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working code - single rf params not grid\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500)\n",
    "clf_rf.fit(X_train_pca, y_train.values.ravel())\n",
    "\n",
    "#steps = [('pca', PCA(n_components=7)),\n",
    "#         ('clf', RandomForestClassifier(max_depth=2, random_state=42, oob_score=True, n_estimators=500))]\n",
    "#pipe = Pipeline(steps)\n",
    "\n",
    "#pipe.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Obtain the OOB error\n",
    "oob_error = 1 - clf_rf.oob_score_\n",
    "  \n",
    "# Print the OOB error\n",
    "print('OOB error:', oob_error.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to try and run\n",
    "# knc with grid search and cross validation\n",
    "\n",
    "param_grid_knc = [{\n",
    "    'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "    'clf__weights': ['uniform','distance'],\n",
    "    'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "    'clf__p': [1,2],\n",
    "    #'class_weights': ['balanced']\n",
    "}]\n",
    "\n",
    "def tune_model (clf, param_grid, score_method):\n",
    "    \n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    pipeline = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', clf)])\n",
    "\n",
    "    CV = GridSearchCV(pipeline, param_grid, scoring = score_method, n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel())\n",
    "    print('Best score:', CV.best_score_)\n",
    "    print('\\nBest parameter combination:', CV.best_params_)\n",
    "    return\n",
    "\n",
    "tune_model(KNeighborsClassifier(), param_grid_knc, 'f1_macro')\n",
    "# should scoring method be accuracy here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying xgb code for knc 10 May 23\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "#param_grid_knn = [{\n",
    "#    'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "#    'clf__weights': ['uniform','distance'],\n",
    "#    'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "#    'clf__p': [1,2]\n",
    "#}]\n",
    "\n",
    "def single_knc (n_neighbors, weights, leaf_size, p):\n",
    "    # run a single knc model given parameters and return the error\n",
    "\n",
    "    clf=KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, \n",
    "                             leaf_size=leaf_size, p=p)\n",
    "\n",
    "    \n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "    clf.fit(X_train, y_train.values.ravel(), eval_set=eval_set, verbose=True)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Obtain accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "        \n",
    "max_depth = [3,4,5,6]\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.4]\n",
    "subsample = [0.5, 1.0, 0.1]\n",
    "gamma = [1,2,3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "colsample_bytree = [0.1, 0.5, 1]\n",
    "min_child_weight = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "accuracy = []\n",
    "params = []\n",
    "\n",
    "for a in max_depth:\n",
    "    for b in learning_rate:\n",
    "        for c in subsample:\n",
    "            for d in gamma:\n",
    "                for e in colsample_bytree:\n",
    "                    for f in min_child_weight:\n",
    "                        acc = single_xgb(a, b, c, d, e, f)\n",
    "                        accuracy.append(acc)\n",
    "                        params.append([a,b,c,d,e,f])\n",
    "    \n",
    "df = pd.DataFrame({'accuracy':accuracy, 'params': params})\n",
    "df_max = df[df.accuracy == df.error.max()]\n",
    "df_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577554b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial\n",
    "\n",
    "param_grid_knn = [{\n",
    "    'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "    'clf__weights': ['uniform','distance'],\n",
    "    'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "    'clf__p': [1,2]\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "# rf scoring method = oob_score_\n",
    "param_grid_rf = [{\n",
    "    'n_estimators':[100, 500, 1000, 2000, 3000, 4000, 5000], \n",
    "    'max_features': ['log2', 'sqrt', 'None'], \n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True], \n",
    "    'oob_score': True,\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state':42,\n",
    "    'max_samples': 0.8,\n",
    "    'warm_start':True\n",
    "}]\n",
    "\n",
    "\n",
    "#    param_grid_lgb = {\n",
    "#        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss']),\n",
    "#        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "#        'num_leaves': trial.suggest_int('num_leaves', 2, 256, log=True),\n",
    "#        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "#        'min_child_samples': trial.suggest_int('min_child_samples', 2, 256, log=True),\n",
    "#        'bagging_freq': trial.suggest_categorical('bagging_freq', [0, 1]),\n",
    "#        'pos_bagging_fraction': trial.suggest_float('pos_bagging_fraction', 0.1, 1),\n",
    "#        'neg_bagging_fraction': trial.suggest_float('neg_bagging_fraction', 0.1, 1),\n",
    "#        'reg_alpha': trial.suggest_float('reg_alpha', 0.00001, 0.1, log=True),\n",
    "#        'reg_lambda': trial.suggest_float('reg_lambda', 0.00001, 0.1, log=True),\n",
    "#    }\n",
    "    \n",
    "    \n",
    "param_grid_xgb = [{\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'subsample': [0.5, 1.0, 0.1],\n",
    "    'gamma': [1,2,3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "    'colsample_bytree' : [0.1, 0.5, 1],\n",
    "    'min_child_weight' : [0,1,2,3,4,5,6,7,8,9],\n",
    "    ###    'n_estimators': 180,\n",
    "    'seed': 42\n",
    "}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4451ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {#'Logistic Regression': LogisticRegression(max_iter = 5000, multi_class='auto', random_state=42),#\n",
    "         'Random Forest': RandomForestClassifier(random_state=42),\n",
    "          'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "          'Naive Bayes': GaussianNB(),\n",
    "          'Support Vector Machine': SVC(max_iter = 5000, random_state=42),\n",
    "          'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "          'XGBoost': XGBClassifier(random_state=42),\n",
    "          'Light Gradient Boosting': LGBMClassifier(random_state=42),\n",
    "          'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "         }\n",
    "\n",
    "\n",
    "def execute_model (models):\n",
    "    \n",
    "    # Create a dataframe of model names and the mean f1 macro averaged score \n",
    "    # across five folds using StratifyKFold\n",
    "\n",
    "    model_names_list = []\n",
    "    model_means_list = []\n",
    "\n",
    "    for name, model, in models.items():\n",
    "        \n",
    "        # execute each model from list of models\n",
    "        steps = [('pca', PCA(n_components=7)),\n",
    "                 ('clf', model)]\n",
    "        pipe = Pipeline(steps)\n",
    "        k = 5\n",
    "        cv = StratifiedKFold(n_splits=k, random_state=4, shuffle=True)\n",
    "        \n",
    "        # get the f1 macro averaged score for each fold and then find the mean\n",
    "        scores = cross_val_score(pipe, X_train, y_train.values.ravel(), scoring='f1_macro', cv=cv)\n",
    "        mean = np.mean(scores).round(5)\n",
    "        \n",
    "        # appeand the names and means to lists\n",
    "        model_names_list.append(name)\n",
    "        model_means_list.append(mean)\n",
    "        \n",
    "    # create a dataframe from the lists\n",
    "    model_df = pd.DataFrame({'names':model_names_list, 'mean score': model_means_list})\n",
    "\n",
    "    return model_df\n",
    "\n",
    "# sort the dataframe by mean score in descending order and print\n",
    "print('Mean of f1 macro average from 5 stratified folds on training data for out of the box models:')\n",
    "model_df = execute_model(models)\n",
    "model_df = model_df.sort_values(by = 'mean score', ascending=False)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = [\n",
    "    {'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "     'clf__weights': ['uniform','distance'],\n",
    "     'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "     'clf__p': [1,2]}\n",
    "]\n",
    "\n",
    "\n",
    "tune_model(KNeighborsClassifier(), param_grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970af3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune SVM\n",
    "\n",
    "param_grid_svm = [{\n",
    "    'clf__kernel': ['linear','poly','rbf','sigmoid'],\n",
    "    'clf__C': [0.1,1,10,100],\n",
    "    'clf__gamma': [1,0.1,0.01,0.001]\n",
    "}]\n",
    "\n",
    "\n",
    "tune_model(SVC(max_iter = 5000, random_state=42), param_grid_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65608d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare f1 macro avg fro baseline, knn, svm\n",
    "\n",
    "#Log Reg Best score: 0.9986573963078399\n",
    "\n",
    "tuned_models = {'Logistic Regression': LogisticRegression(random_state=42, max_iter = 5000,\n",
    "                                                          multi_class='ovr',penalty='l1', \n",
    "                                                          solver='liblinear'),\n",
    "                'K-Nearest Neighbors': KNeighborsClassifier(leaf_size=2, n_neighbors=2,\n",
    "                                                           p=1, weights='uniform'),\n",
    "                'Support Vector Machine': SVC(max_iter = 5000, random_state=42, C=0.1,\n",
    "                                             gamma=1, kernel='linear'),\n",
    "}\n",
    "\n",
    "# sort the dataframe by mean score in descending order and print\n",
    "print('Mean of f1 macro average from 5 stratified folds on training data for tuned models:')\n",
    "model_df_tuned = execute_model(tuned_models)\n",
    "model_df_tuned = model_df_tuned.sort_values(by = 'mean score', ascending=False)\n",
    "model_df_tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a knn model with the best parameters found in grid search\n",
    "pipe_knn = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', KNeighborsClassifier(leaf_size=2, n_neighbors=2,\n",
    "                                                           p=1, weights='uniform'))])\n",
    "\n",
    "get_folds(pipe_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a svm model with the best parameters found in grid search\n",
    "pipe_svm = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', SVC(max_iter = 5000, random_state=42, C=0.1,\n",
    "                                             gamma=1, kernel='linear'))])\n",
    "\n",
    "get_folds(pipe_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55410fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial xgb\n",
    "# without grid search\n",
    "clf=XGBClassifier(max_depth=3, learning_rate=0.1, subsample=0.5, gamma=1, \n",
    "                  colsample_bytree=0.1, min_child_weight=0, early_stopping_rounds=10, \n",
    "                  eval_metric='merror')\n",
    "eval_set = [(X_test, y_test)]\n",
    "clf.fit(X_train, y_train.values.ravel(), eval_set=eval_set, verbose=True)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial xgb\n",
    "# reduced parameter grid for speed\n",
    "\n",
    "param_grid_xgb = [{\n",
    "    'clf__max_depth': [3,4],\n",
    "    'clf__learning_rate': [0.1],\n",
    "    'clf__subsample': [0.5],\n",
    "    'clf__gamma': [1],\n",
    "    'clf__colsample_bytree' : [0.1],\n",
    "    'clf__n_estimators':[200],\n",
    "    'clf__min_child_weight' : [0,1],\n",
    "    'clf__seed': [42],\n",
    "    'clf__early_stopping_rounds': [10],\n",
    "    'clf__eval_metric': ['merror']\n",
    "}]\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "def tune_model (clf, param_grid):\n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "\n",
    "    CV = GridSearchCV(clf, param_grid, n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel(), eval_set=eval_set)\n",
    "    print('Best score:', CV.best_score_)\n",
    "    print('\\nBest parameter combination:', CV.best_params_)\n",
    "    return\n",
    "\n",
    "#tune_model(LogisticRegression(random_state=42, max_iter = 5000), param_grid_lr, 'f1_macro')\n",
    "tune_model(XGBClassifier(), param_grid_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial xgb\n",
    "\n",
    "param_grid_xgb = [{\n",
    "    'clf__max_depth': [3,4,5,6],\n",
    "    'clf__learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'clf__subsample': [0.5, 1.0, 0.1],\n",
    "    'clf__gamma': [1,2,3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "    'clf__colsample_bytree' : [0.1, 0.5, 1],\n",
    "    'clf__min_child_weight' : [0,1,2,3,4,5,6,7,8,9],\n",
    "    ###    'n_estimators': 180,\n",
    "    'clf__seed': [42]\n",
    "}]\n",
    "\n",
    "def tune_model (clf, param_grid, score_method):\n",
    "    \n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    pipeline = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', clf)])\n",
    "\n",
    "    CV = GridSearchCV(pipeline, param_grid, scoring = score_method, n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel())\n",
    "    print('Best score:', CV.best_score_)\n",
    "    print('\\nBest parameter combination:', CV.best_params_)\n",
    "    return\n",
    "\n",
    "#tune_model(LogisticRegression(random_state=42, max_iter = 5000), param_grid_lr, 'f1_macro')\n",
    "tune_model(XGBClassifier(), param_grid_xgb, 'f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knc with randomized search and cross validation\n",
    "# research scorer_\n",
    "\n",
    "param_grid_knc = [{\n",
    "    #'clf__n_neighbors': [1,2,3,4,5,10], \n",
    "    'clf__n_neighbors': list(range(1,10)),\n",
    "    'clf__weights': ['uniform','distance'],\n",
    "    #'clf__leaf_size': [2,4,6,8,10,15,20,25,30],\n",
    "    'clf__leaf_size': list(range(2,30)),\n",
    "    'clf__p': [1,2],\n",
    "    #'clf__class_weights': ['balanced']\n",
    "}]\n",
    "\n",
    "def tune_model (clf, param_grid, score_method):\n",
    "    \n",
    "    #perform grid search to find the best parameters for a model\n",
    "    \n",
    "    pipeline = Pipeline([('pca', PCA(n_components=7)),\n",
    "                        ('clf', clf)])\n",
    "\n",
    "    CV = RandomizedSearchCV(pipeline, param_grid, scoring = score_method, \n",
    "                            n_iter=10, cv=5, n_jobs= 1)\n",
    "    CV.fit(X_train, y_train.values.ravel())\n",
    "    best_score = CV.best_score_\n",
    "    best_params = CV.best_params_\n",
    "    #print('Best score:', CV.best_score_)\n",
    "    #print('\\nBest parameter combination:', CV.best_params_)\n",
    "    \n",
    "    return best_score, best_params\n",
    "\n",
    "best_score_knc, best_params_knc = tune_model(KNeighborsClassifier(), param_grid_knc, 'f1_macro')\n",
    "# should scoring method be f1_macro here?\n",
    "\n",
    "print('Best score knc:', best_score_knc)\n",
    "print('\\nBest parameter combination knc:', best_params_knc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best_params to run the knc model\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.set_params(**best_params_knc)\n",
    "model.fit(X_test, y_test.values.ravel())\n",
    "score = model.score(X_test, y_test.values.ravel())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0048a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                        errors.append(oob_e)\n",
    "#                        params.append([['n_estimators',a],['max_features',b],\n",
    "#                                       ['max_depth',c],['min_samples_leaf',d],\n",
    "#                                       ['min_samples_split',e],['criterion',f]])\n",
    "\n",
    "\n",
    "#df = pd.DataFrame({'error':errors, 'params': params})\n",
    "#df_min = df[df.error == df.error.min()]\n",
    "#df_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06448389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                        params.append([['max_depth',a],['learning_rate',b],\n",
    "#                                       ['subsample',c],['gamma',d],\n",
    "#                                       ['colsample_bytree',e],['min_child_weight',f]])\n",
    "\n",
    "    \n",
    "#df = pd.DataFrame({'accuracy':accuracy, 'params': params})\n",
    "#df_max = df[df.accuracy == df.accuracy.max()]\n",
    "#df_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    clf_knc = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,\n",
    "#                                  leaf_size=leaf_size, p=p)\n",
    "#    clf_knc.fit(X_train_pca, y_train.values.ravel())\n",
    "\n",
    "\n",
    "    #print('Best score:', CV.best_score_)\n",
    "    #print('\\nBest parameter combination:', CV.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying rf code for XGBoost 10 May 23\n",
    "# working but need to check what I'm measuring and reduce runtime\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "def single_xgb (max_depth, learning_rate, subsample, gamma, \n",
    "                colsample_bytree, min_child_weight):\n",
    "    # run a single xgb model given parameters and return the error\n",
    "\n",
    "    clf=XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, \n",
    "                      subsample=subsample, gamma=gamma, \n",
    "                      colsample_bytree=colsample_bytree, \n",
    "                      min_child_weight=min_child_weight, \n",
    "                      early_stopping_rounds=10, \n",
    "                      eval_metric='merror')\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    clf.fit(X_train, y_train.values.ravel(), eval_set=eval_set, verbose=False)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Obtain accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "        \n",
    "#max_depth = [3,4,5,6]\n",
    "#learning_rate = [0.1, 0.2, 0.3, 0.4]\n",
    "#subsample = [0.5, 1.0, 0.1]\n",
    "#gamma = [1,2,3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "#colsample_bytree = [0.1, 0.5, 1]\n",
    "#min_child_weight = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "max_depth = [3,4,5,6]\n",
    "learning_rate = [0.1]\n",
    "subsample = [0.5]\n",
    "gamma = [1]\n",
    "colsample_bytree = [0.1]\n",
    "min_child_weight = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "accuracy = 0\n",
    "params_xgb = []\n",
    "\n",
    "for a in max_depth:\n",
    "    for b in learning_rate:\n",
    "        for c in subsample:\n",
    "            for d in gamma:\n",
    "                for e in colsample_bytree:\n",
    "                    for f in min_child_weight:\n",
    "                        acc = single_xgb(a, b, c, d, e, f)\n",
    "                        if acc>accuracy:\n",
    "                            \n",
    "                            accuracy = acc\n",
    "                            params_xgb.clear()\n",
    "                            params_xgb.append(a)\n",
    "                            params_xgb.append(b)\n",
    "                            params_xgb.append(c)\n",
    "                            params_xgb.append(d)\n",
    "                            params_xgb.append(e)\n",
    "                            params_xgb.append(f)\n",
    "                        else:\n",
    "                            continue\n",
    "    \n",
    "    \n",
    "param_names_xgb = ['max_depth','learning_rate','subsample','gamma','colsample_bytree','min_child_weight']\n",
    "best_params_xgb = dict(zip(param_names_xgb, params_xgb))\n",
    "print('Best xgb params:', best_params_xgb)\n",
    "print('\\nAccuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026802a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(5):\n",
    "#    shap.force_plot(explainer.expected_value[i], shap_values[i], X)\n",
    "\n",
    "#shap.force_plot(explainer.expected_value[0], shap_values[0], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(shap.force_plot(explainer.expected_value[0], shap_values[0], X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b24337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = 0\n",
    "#for i in range(5):\n",
    "#    shap.force_plot(explainer.expected_value[i], shap_values[i][row], X.values[row], feature_names = X.columns)\n",
    "\n",
    "#for i in range(5):\n",
    "#    shap.force_plot(explainer.expected_value[i], shap_values[i][row], X.values[row], feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf273649",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = y.index[y['Class']==0].min().tolist()\n",
    "y_1 = y.index[y['Class']==1].min().tolist()\n",
    "y_2 = y.index[y['Class']==2].min().tolist()\n",
    "y_3 = y.index[y['Class']==3].min().tolist()\n",
    "y_4 = y.index[y['Class']==4].min().tolist()\n",
    "\n",
    "ys = ['y_0','y_1','y_2','y_3','y_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f00553",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knc_all = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knc_all.set_params(**best_params_knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knc_all.fit(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f432091",
   "metadata": {},
   "source": [
    "Here again, but in greater detail, we can see the lack of overlap between the features that are important for each class.  The only genes which are repeated between any two classes occur between kidney and color cancer, and the SHAP values reflecting the impact on the model output magnitude of those genes are so small as to be imperceptible from zero.  Prostate cancer is again noteable because it has only the single feature, gene_203, which bears any perceivable impact on the model output magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06a37c",
   "metadata": {},
   "source": [
    "Watefall plots allow us to see the impact and direction of impact of each feature for a single prediction.  I will look at one prediction for each class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = ['0: BRCA (breast)','1: COAD (colon)','2: KIRC (kidney)','3: LUAD lLung)','4: PRAD (prostate)']\n",
    "\n",
    "#for i in range(5):\n",
    "#    message = f\"Class {a[i]}\"\n",
    "#    plt.title(message)\n",
    "#    shap.summary_plot(shap_values[i], X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94742ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = 5\n",
    "\n",
    "#for i in range(5):\n",
    "#    message = f\"Class {a[i]}\"\n",
    "#    plt.title(message)\n",
    "#    shap.waterfall_plot(shap.Explanation(values=shap_values[i][row], \n",
    "#                                         base_values=explainer.expected_value[i], \n",
    "#                                         data=X.iloc[row],  \n",
    "#                                         feature_names=X.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042482c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.initjs()\n",
    "#print(\"Contributing Features for Single Model Prediction in Class 0: BRCA (breast)\")\n",
    "#shap.force_plot(explainer.expected_value[0], shap_values[0][row], X.values[row], feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b43bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(5):\n",
    "#    message = f\"Class {a[i]}\"\n",
    "#    plt.title(message)\n",
    "#    shap.summary_plot(shap_values[i], X, max_display=10)\n",
    "\n",
    "\n",
    "#for i in list(range(5)):\n",
    "#    print(\"Summary Plot for Class\", i)\n",
    "#    shap.summary_plot(shap_values[i], X, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31288d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Naive Bayes': GaussianNB(),\n",
    "          'Support Vector Classifier': SVC(max_iter = 5000, random_state=42),}\n",
    "\n",
    "def execute_linear_model (models):\n",
    "    \n",
    "    # Create a dataframe of model names and the mean f1 macro averaged score \n",
    "    # across five folds using StratifyKFold\n",
    "\n",
    "    model_names_list = []\n",
    "    model_train_means_list = []\n",
    "    model_test_list = []\n",
    "\n",
    "    for name, model, in models.items():\n",
    "        \n",
    "        # execute each model from list of models\n",
    "        steps = [('pca', PCA(n_components=7)),\n",
    "                 ('clf', model)]\n",
    "        pipe = Pipeline(steps)\n",
    "        k = 5\n",
    "        cv = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n",
    "        \n",
    "        # get the f1 macro averaged score for each fold and then find the mean\n",
    "        scores_train = cross_val_score(pipe, X_train, y_train.values.ravel(), scoring='f1_macro', cv=cv)\n",
    "        mean = np.mean(scores_train).round(5)\n",
    "        \n",
    "        # appeand the names and means to lists\n",
    "        model_names_list.append(name)\n",
    "        model_train_means_list.append(mean)\n",
    "    \n",
    "        #scores_test = pipe(X_test, y_test.values.ravel(), scoring='f1_macro')\n",
    "        pipe.fit(X_train, y_train.values.ravel())\n",
    "        y_test_pred = pipe.predict(X_test)\n",
    "        scores_test = f1_score(y_test, y_test_pred, average='macro')\n",
    "        model_test_list.append(scores_test)\n",
    "        \n",
    "    \n",
    "    # create a dataframe from the lists\n",
    "    model_df = pd.DataFrame({'names':model_names_list, 'mean train score': model_train_means_list, 'test score': model_test_list})\n",
    "\n",
    "    return model_df\n",
    "\n",
    "# sort the dataframe by mean score in descending order and print\n",
    "print('Linear models f1 macro scores:')\n",
    "model_df= execute_linear_model(models)\n",
    "model_df = model_df.sort_values(by = 'test score', ascending=False)\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96399c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d656188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
